[
  {
    "objectID": "archived_posts/trustless-ham/index.html",
    "href": "archived_posts/trustless-ham/index.html",
    "title": "Trustless Radio Broadcasting",
    "section": "",
    "text": "Tonight I am wondering on why my recent “SineWave Residual Modulation” might be useful and I think it has something to do with “trust” or… more enigmatically stated: “shared language”. Supersampling a sinusoidal signal and finding a steady signal in the residuals could be a way to encrypt information. Any swath of spacetime where the lower-frequency timing signal would be detectable would have access to the key, and messages on higher-frequencies could be decrypted using that key. The supersampling frequency would be the same as the new recieving frequency.\nBut also maybe I am having some confusion about how the antenna systems work. I am trying to read about “Software Defined Radio” but still struggling with some concepts.\nAn antenna (or perhaps more accurately, an RF Frontend) is designed to pick up ((and/or?) transmit) a specific frequency. At this selected frequency a signal is detected and can be captured as a time-series. The processing I am referring to takes place within a detected periodic signal within this time-series. It is confusing to describe but I think a lower-frequency pattern can be transmitted in a higher-frequency medium. Imagine tuning to a radio station and hearing a single tone. But then within this tone would be tiny variations between each wave period. These variations could be processed using the methods from my previous post and the message found as sampled at the frequency of the analog-to-digital converter.\nThe frequency of the A2D converter could then be used as a broadcast frequency on which to broadcast messages encrypted by the message found on the original radio station.\nWe can imagine a system of “major stations” with the power to broadcast & recieve widely a signal, and “minor stations” which operate more locally.\n\n\n\nmesh depcition\n\n\nA “Major station” signal can act as decoding key for minor station signals.\nlow freq message can be used to encrypt higher freq messages.\nmulti-frequency stations input higher-freq messages and choose to continue outputting current message or begin rebroadcasting message from higher-freq transmitting neighbor.\nSo here we have a “trustless” ham radio encryption system? Little stations can speak to each other while blessed by the wider transmission. Stations outside of the spacetime covered by the major station will only be able to understand other minor stations if they have memory of the major station transmission."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Tylar’s Blog",
    "section": "",
    "text": "Seagrass Change Over Time in FL Bay\n\n\n\n\n\n\n\n\nJan 29, 2026\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nSeagrass Time Series for St Andrew’s Bay, FL\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nMangrove Mapping with NASA Prithvi-EO\n\n\n\n\n\n\n\n\nDec 28, 2025\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nShould Land Masking Be Applied for GeoFM Tuning Datasets?\n\n\n\n\n\n\n\n\nDec 28, 2025\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nSeagrass Mapping with NASA Prithvi-EO\n\n\n\n\n\n\n\n\nDec 12, 2025\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nLaptop HDD RePartition\n\n\n\n\n\n\n\n\nFeb 20, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nChoosing Images for Rookery Bay NERR in GEE\n\n\n\n\n\n\n\n\nJan 25, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nCalCOFI Server Clone Attempt\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nPhytoclass GUI Updates\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nRainbow River Trek 2024-01\n\n\n\n\n\n\n\n\nJan 15, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nBrainstorming USF Libraries Researcher Workshop Topics\n\n\n\n\n\n\n\n\nJan 4, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nBus Victron Electrical Connection\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nGEE DwC-like Ground Truth for USVI Corals\n\n\n\n\n\n\n\n\nDec 28, 2023\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Blog Config\n\n\n\n\n\n\n\n\nDec 27, 2023\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Blog Init\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\n{{POSTTITLE}}\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nTylar\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2026-01_seagrass-change-fl-bay/index.html",
    "href": "posts/2026-01_seagrass-change-fl-bay/index.html",
    "title": "Seagrass Change Over Time in FL Bay",
    "section": "",
    "text": "Here we examine change over time for an area in Florida Bay with the intent of identifying change in seagrass coverage.\nTwo regions of interest were identified. The first is an area of seagrass coverage in Florida Bay. The second is an area of nearby deep water.\nThis GEE script was used to extract spectral values over time from harmonized spectral imagery. A cloud mask was applied using the CloudScore+ product. The spectral bands were normalized relative to the average of all bands. Roughly 2300 individual images were composited using a mean into a set of ~650 daily images.\nThe data is available in this gSheet.\nThe Submerged Seagrasses Identification Index 1 was calculated and visualized with a center-adjusted moving average with window size 10.\nThe seasonal signal is clear, however, a seasonal signal is also clear in a time series extracted from the nearby deep water area. Although this image product is adjusted for atmospheric and sun angle effects, some seasonal signal remains.\nAn adjusted SSII was computed to remove seasonal affects that are not related to seagrass growth itself. The same extraction was performed for the FL-Bay area and the nearby area of deep water. The SSII was computed for both regions. The deep water SSII was subtracted from the FL Bay SSII. The remaining signal is an indication of change that is independent of remote sensing changes in the larger region.\nIn this series the expected seasonality is still apparent. Seagrass coverage is expected to decrease in the winter and increase in the summer. The summer maximums are stable when compared to the winter minimums, which show more variablity.\nThe winters of 2022 and 2023 stand out as seasons of unusually low SSII. A potential cause of this anomaly could not be identified."
  },
  {
    "objectID": "posts/2026-01_seagrass-change-fl-bay/index.html#footnotes",
    "href": "posts/2026-01_seagrass-change-fl-bay/index.html#footnotes",
    "title": "Seagrass Change Over Time in FL Bay",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://pubmed.ncbi.nlm.nih.gov/36682175/↩︎"
  },
  {
    "objectID": "posts/2024-02_laptop-hdd-repartition/index.html",
    "href": "posts/2024-02_laptop-hdd-repartition/index.html",
    "title": "Laptop HDD RePartition",
    "section": "",
    "text": "My laptop hard drive is “full”.\nsudo fdisk -l\n[...]\nDisk /dev/nvme0n1: 476.94 GiB, 512110190592 bytes, 1000215216 sectors\nDisk model: HFM512GD3JX013N                         \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: CC82F627-8A27-4326-9940-38E19AA36263\n\nDevice             Start        End   Sectors   Size Type\n/dev/nvme0n1p1      2048     534527    532480   260M EFI System\n/dev/nvme0n1p2    534528     567295     32768    16M Microsoft reserved\n/dev/nvme0n1p3    567296  586504795 585937500 279.4G Microsoft basic data\n/dev/nvme0n1p4 999168000 1000214527   1046528   511M Windows recovery environment\n/dev/nvme0n1p5 586506240  977129471 390623232 186.3G Linux filesystem\n/dev/nvme0n1p6 977129472  999165951  22036480  10.5G Linux swap\n\nPartition table entries are not in disk order.\nIt looks like a lot of that space is being wasted by something called “Microsoft Windows” - maybe some kind of virus. Let’s clear those partitions and free them up for something useful.\nthere we go:\nsudo fdisk -l\n[...]\nDisk /dev/nvme0n1: 476.94 GiB, 512110190592 bytes, 1000215216 sectors\nDisk model: HFM512GD3JX013N                         \nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: CC82F627-8A27-4326-9940-38E19AA36263\n\nDevice             Start       End   Sectors   Size Type\n/dev/nvme0n1p1      2048    534527    532480   260M EFI System\n/dev/nvme0n1p5 586506240 977129471 390623232 186.3G Linux filesystem\n/dev/nvme0n1p6 977129472 999165951  22036480  10.5G Linux swap"
  },
  {
    "objectID": "posts/2024-01_calcofi-clone/index.html",
    "href": "posts/2024-01_calcofi-clone/index.html",
    "title": "CalCOFI Server Clone Attempt",
    "section": "",
    "text": "Attempting to clone the CalCOFI server to see if we can reuse the docker config.\ngit clone git@github.com:CalCOFI/server.git\necho 'PASSWORD=Cc!' &gt; .env\n\n# docker launch as daemon\ndocker compose up -d\nFound and fixed a simple syntax error in the docker-compose.yaml. Then ran out of disk space on my laptop."
  },
  {
    "objectID": "posts/2025-12_prithvi-landmask-or-not/index.html",
    "href": "posts/2025-12_prithvi-landmask-or-not/index.html",
    "title": "Should Land Masking Be Applied for GeoFM Tuning Datasets?",
    "section": "",
    "text": "Results of Seagrass Classification with Prithvi-EO using land-masked spectral files and non-land-masked spectral files."
  },
  {
    "objectID": "posts/2025-12_prithvi-landmask-or-not/index.html#spectral-images",
    "href": "posts/2025-12_prithvi-landmask-or-not/index.html#spectral-images",
    "title": "Should Land Masking Be Applied for GeoFM Tuning Datasets?",
    "section": "Spectral Images",
    "text": "Spectral Images\nSpectral images are prepared with GEE users/tylarmurray/prithvi:prithvi_s2_median_tif_collection1.\nLine 20 (see below) was removed to create the “unmasked” product.\n   .map(function(img){return img.clip(roi.bb);})\nThe resulting multi-season median composites were built from the following set of images.\nfor 2020:\nHigh Attenuation (Jan-Apr) - Image count:\n72\nTransitional (May-early Jul) - Image count:\n44\nPeak Visibility (Late Jul-Oct) - Image count:\n67\nand for 2024:\nHigh Attenuation (Jan-Apr) - Image count:\n74\nTransitional (May-early Jul) - Image count:\n49\nPeak Visibility (Late Jul-Oct) - Image count:\n72"
  },
  {
    "objectID": "posts/2025-12_prithvi-landmask-or-not/index.html#tuning-patch-sets",
    "href": "posts/2025-12_prithvi-landmask-or-not/index.html#tuning-patch-sets",
    "title": "Should Land Masking Be Applied for GeoFM Tuning Datasets?",
    "section": "Tuning Patch-Sets",
    "text": "Tuning Patch-Sets\nTuning patches were extracted from each 2023-2025 median image and the SIMM seagrass map.\n(base) tylar@tylar-laptop:~/repos/nasa-prithvi-wetlands$ python scripts/extract_tuning_patches_seagrass_2class_sentinel2.py \nClearing existing output directory: data/output/tuning_patches\n\n============================================================\nCRS mismatch detected: EPSG:4326 vs EPSG:3746\nReprojecting mask to match spectral image...\nMask reprojected to match spectral image: (1306, 1585)\n\nExtracting 224x224 patches with stride 224\nNumber of spectral bands: 24\nWill extract up to 35 patches from this shard\n\nShard complete: 22 valid patches extracted\n\n============================================================\nExtraction complete!\n============================================================\nSpectral files processed: 1\nValid patches saved: 22\nPatches skipped: 13\nOutput directory: data/output/tuning_patches\n\nOrganizing patches into training and validation sets...\n\nDataset split created:\nTraining samples: 18\n  - Files in: data/output/tuning_patches/training_chips\n  - List file: training_data.txt\nValidation samples: 4\n  - Files in: data/output/tuning_patches/validation_chips\n  - List file: validation_data.txt\n\nChip naming format:\n  - Spectral: chip_XXXXX_merged.tif\n  - Mask: chip_XXXXX.mask.tif\n\nCleaning up temporary directories...\n  - Removed: data/output/tuning_patches/spectral\n  - Removed: data/output/tuning_patches/masks\n✓ Cleanup complete!\n\n✓ Patch extraction complete! Ready for Prithvi fine-tuning.\nNOTE: This number of tuning samples may be too low for tuning to be effective."
  },
  {
    "objectID": "posts/2025-12_prithvi-landmask-or-not/index.html#research-notebook-changes",
    "href": "posts/2025-12_prithvi-landmask-or-not/index.html#research-notebook-changes",
    "title": "Should Land Masking Be Applied for GeoFM Tuning Datasets?",
    "section": "Research Notebook Changes",
    "text": "Research Notebook Changes\nThe following line is adjusted to use the unmasked or mask product:\nUNSEEN_IMAGE_FNAME = \"stAndrews_seasonal_s2_stack_2019_to_2021_unmasked.tif\""
  },
  {
    "objectID": "posts/2025-12_prithvi-landmask-or-not/index.html#results",
    "href": "posts/2025-12_prithvi-landmask-or-not/index.html#results",
    "title": "Should Land Masking Be Applied for GeoFM Tuning Datasets?",
    "section": "Results",
    "text": "Results\nWith Landmask: \nWithout Landmask:"
  },
  {
    "objectID": "posts/2023-12_gee-multih-usvi/index.html",
    "href": "posts/2023-12_gee-multih-usvi/index.html",
    "title": "GEE DwC-like Ground Truth for USVI Corals",
    "section": "",
    "text": "Working with Chelsea Bryant today to import some satellite-derived benthic species data into google earth engine. I have done similar things before with Rookery Bay and Jobos Bay NERRS so I want to reuse some methods. I didn’t do a good job documenting things last time so I hope to improve that along the way.\nI dug into the various scripts and was not able to make any progress. I forgot to take notes here; I will have to come back to this later."
  },
  {
    "objectID": "posts/2025-12_prithvi-mangrove/index.html",
    "href": "posts/2025-12_prithvi-mangrove/index.html",
    "title": "Mangrove Mapping with NASA Prithvi-EO",
    "section": "",
    "text": "An attempt to fine-tune Prithvi-EO to produce mangrove classification maps.\nThis work is based on previous post Seagrass Mapping with NASA Prithvi-EO.\nCode related to this post is stored in 7yl4r/nasa-prithvi-wetlands."
  },
  {
    "objectID": "posts/2025-12_prithvi-mangrove/index.html#spectral-training-input",
    "href": "posts/2025-12_prithvi-mangrove/index.html#spectral-training-input",
    "title": "Mangrove Mapping with NASA Prithvi-EO",
    "section": "Spectral Training Input",
    "text": "Spectral Training Input\nA sentinel-2 spectral median was prepared for the RoI. This GEE script was used to generate the file.\nThe CloudScorePlus product was used with a threshold of 0.80 to filter clouds. The recommended value for the threshold is 0.65, but for this region the 0.8 was required to remove visable hazes in the median product.\nImages from years 2023-2025 were used in three distinct seasons.\nHigh Attenuation (Jan-Apr) - Image count:\n663\nTransitional (May-early Jul) - Image count:\n439\nPeak Visibility (Late Jul-Oct) - Image count:\n642\nThe file is placed in data/inputs/spectral/TTI_seasonal_s2_stack.tif."
  },
  {
    "objectID": "posts/2025-12_prithvi-mangrove/index.html#mangrove-classification-map-training-input",
    "href": "posts/2025-12_prithvi-mangrove/index.html#mangrove-classification-map-training-input",
    "title": "Mangrove Mapping with NASA Prithvi-EO",
    "section": "Mangrove Classification Map Training Input",
    "text": "Mangrove Classification Map Training Input\nThe LANDSAT/MANGROVE_FORESTS layer produced by Giri et alii from GEE was used. This GEE script was used to export the file data/inputs/classmaps/TTI_mangrove_landsat_Giri.tif."
  },
  {
    "objectID": "posts/2025-12_prithvi-mangrove/index.html#evaluation-spectral-image",
    "href": "posts/2025-12_prithvi-mangrove/index.html#evaluation-spectral-image",
    "title": "Mangrove Mapping with NASA Prithvi-EO",
    "section": "Evaluation Spectral Image",
    "text": "Evaluation Spectral Image\nAn image was prepared for the tuned classifier to be used upon, TTI_seasonal_s2_stack_2019_to_2021.tif.\nMethods matching the Spectral Training Input file above were used for the years 2019-2021.\nHigh Attenuation (Jan-Apr) - Image count:\n673\nTransitional (May-early Jul) - Image count:\n408\nPeak Visibility (Late Jul-Oct) - Image count:\n581\nThe file was uploaded to GDrive for access from colab notebooks."
  },
  {
    "objectID": "posts/2025-12_prithvi-mangrove/index.html#preparation-of-fine-tuning-patch-chips",
    "href": "posts/2025-12_prithvi-mangrove/index.html#preparation-of-fine-tuning-patch-chips",
    "title": "Mangrove Mapping with NASA Prithvi-EO",
    "section": "Preparation of Fine-Tuning Patch Chips",
    "text": "Preparation of Fine-Tuning Patch Chips\nThe input files were downloaded and a script was used to cut these images into into sets of chips. The required script(s) can be found in the 7yl4r/prithvi-hab repo.\n(base) tylar@tylar-laptop:~/repos/nasa-prithvi-wetlands$ python scripts/extract_tuning_patches_mangrove_sentinel2.py \nClearing existing output directory: data/output/tuning_patches\nDetected single TIF file: data/input/spectral/TTI_seasonal_s2_stack.tif\n\n============================================================\nProcessing spectral file 1/1: TTI_seasonal_s2_stack.tif\n============================================================\nSpectral CRS: EPSG:4326\nMask CRS: EPSG:4326\nSpectral bounds (native): BoundingBox(left=-81.90290788278485, bottom=25.280748051805226, right=-80.7931291807836, top=26.05823993021067)\nMask bounds (native): BoundingBox(left=-81.90290788278485, bottom=25.280748051805226, right=-80.7931291807836, top=26.05823993021067)\n\nOverlap bounds (in spectral CRS): left=-81.90, bottom=25.28, right=-80.79, top=26.06\n\nSpectral file shape: (2885, 4118)\nMask file shape: (2885, 4118)\nOverlap region: 2885x4118 pixels\nSpectral window: Window(col_off=0, row_off=0, width=4118, height=2885)\nMask window: Window(col_off=0, row_off=0, width=4118, height=2885)\n\n\nExtracting 224x224 patches with stride 224\nNumber of spectral bands: 24\nWill extract up to 216 patches from this shard\n\nExtracted 100 total valid patches...\nExtracted 200 total valid patches...\nShard complete: 216 valid patches extracted\n\n============================================================\nExtraction complete!\n============================================================\nSpectral files processed: 1\nValid patches saved: 216\nPatches skipped: 0\nOutput directory: data/output/tuning_patches\n\nOrganizing patches into training and validation sets...\n\nDataset split created:\nTraining samples: 173\n  - Files in: data/output/tuning_patches/training_chips\n  - List file: training_data.txt\nValidation samples: 43\n  - Files in: data/output/tuning_patches/validation_chips\n  - List file: validation_data.txt\n\nChip naming format:\n  - Spectral: chip_XXXXX_merged.tif\n  - Mask: chip_XXXXX.mask.tif\n\nCleaning up temporary directories...\n  - Removed: data/output/tuning_patches/spectral\n  - Removed: data/output/tuning_patches/masks\n✓ Cleanup complete!\n\n✓ Patch extraction complete! Ready for Prithvi fine-tuning.\n\nCompressing tuning patches...\n✓ Compressed patches saved to: data/output/mangrove_tuning_patches.tar.bz2\nThe file was uploaded to gdrive for the ipnb to use."
  },
  {
    "objectID": "posts/2025-12_prithvi-mangrove/index.html#fine-tuning-research-notebook",
    "href": "posts/2025-12_prithvi-mangrove/index.html#fine-tuning-research-notebook",
    "title": "Mangrove Mapping with NASA Prithvi-EO",
    "section": "Fine Tuning Research Notebook",
    "text": "Fine Tuning Research Notebook\nThe research notebook was developed based on the previous seagrass notebook was created.\nAmong the adjustments needed were: * adjusted filenames * adjusted band names, numbers, etc * adjusted class names, labels, etc\nThe final notebook was lost due to a computer crash, but an early iteration is here."
  },
  {
    "objectID": "posts/2023-12_quarto-blog-init/index.html",
    "href": "posts/2023-12_quarto-blog-init/index.html",
    "title": "Quarto Blog Init",
    "section": "",
    "text": "This first blog post is about setting up this blog. Quarto & RStudio were already set up on my laptop so getting started was easy.\nI set up gh repo in the gh web GUI. Abandoning my last start at https://github.com/7yl4r/tylar.info. There isn’t much there. This time I am using the “blog” template rather than the generic “website”.\nI will use a pretty standard git workflow going forward and not paste in future add, commit, push, etc commands."
  },
  {
    "objectID": "posts/2023-12_quarto-blog-init/index.html#rm-the-template-posts.",
    "href": "posts/2023-12_quarto-blog-init/index.html#rm-the-template-posts.",
    "title": "Quarto Blog Init",
    "section": "Rm the template posts.",
    "text": "Rm the template posts.\n(base) tylar@tylar-gram:~/repos/tylar_info$ rm -rf posts/post-with-code/ posts/welcome/\nI want rendered posts to show on github pages. Some initial setup suggested by this quarto doc.\ngit checkout --orphan gh-pages\ngit reset --hard # make sure all changes are committed before running this!\ngit commit --allow-empty -m \"Initialising gh-pages branch\"\ngit push origin gh-pages\nThis creates the gh-pages branch. If the gh-pages branch does not exist then then next command will throw a cryptic error about _publish.yml.\nI tried quarto publish gh-pages but it hung for several minutes and errored when the computer went to sleep:\n(base) tylar@tylar-gram:~/repos/tylar_info$ quarto publish gh-pages\n? Publish site to https://7yl4r.github.io/tylar_info/ using gh-pages? (Y/n) › Yes\nSaved working directory and index state WIP on main: 6b5f1dd rm template posts\nSwitched to a new branch 'gh-pages'\n[gh-pages (root-commit) d59f058] Initializing gh-pages branch\nremote: \nremote: Create a pull request for 'gh-pages' on GitHub by visiting:        \nremote:      https://github.com/7yl4r/tylar_info/pull/new/gh-pages        \nremote: \nTo github.com:7yl4r/tylar_info.git\n * [new branch]      HEAD -&gt; gh-pages\nYour branch is up to date with 'origin/main'.\nSwitched to branch 'main'\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   posts/quarto-blog-init/index.qmd\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    .Rproj.user/\n    .gitignore\n    tylar_info.Rproj\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nFrom github.com:7yl4r/tylar_info\n * branch            gh-pages   -&gt; FETCH_HEAD\nRendering for publish:\n\n[1/3] about.qmd\n[2/3] posts/quarto-blog-init/index.qmd\n[3/3] index.qmd\n\nPreparing worktree (resetting branch 'gh-pages'; was at d59f058)\nBranch 'gh-pages' set up to track remote branch 'gh-pages' from 'origin'.\nHEAD is now at d59f058 Initializing gh-pages branch\nfatal: pathspec '.' did not match any files\n[gh-pages 799f3a0] Built site for gh-pages\n 30 files changed, 6922 insertions(+)\n create mode 100644 .nojekyll\n create mode 100644 about.html\n create mode 100644 index.html\n create mode 100644 listings.json\n create mode 100644 posts/post-with-code/image.jpg\n create mode 100644 posts/post-with-code/index.html\n create mode 100644 posts/quarto-blog-init/index.html\n create mode 100644 posts/welcome/index.html\n create mode 100644 posts/welcome/thumbnail.jpg\n create mode 100644 profile.jpg\n create mode 100644 search.json\n create mode 100644 site_libs/bootstrap/bootstrap-icons.css\n create mode 100644 site_libs/bootstrap/bootstrap-icons.woff\n create mode 100644 site_libs/bootstrap/bootstrap.min.css\n create mode 100644 site_libs/bootstrap/bootstrap.min.js\n create mode 100644 site_libs/clipboard/clipboard.min.js\n create mode 100644 site_libs/quarto-html/anchor.min.js\n create mode 100644 site_libs/quarto-html/popper.min.js\n create mode 100644 site_libs/quarto-html/quarto-syntax-highlighting.css\n create mode 100644 site_libs/quarto-html/quarto.js\n create mode 100644 site_libs/quarto-html/tippy.css\n create mode 100644 site_libs/quarto-html/tippy.umd.min.js\n create mode 100644 site_libs/quarto-listing/list.min.js\n create mode 100644 site_libs/quarto-listing/quarto-listing.js\n create mode 100644 site_libs/quarto-nav/headroom.min.js\n create mode 100644 site_libs/quarto-nav/quarto-nav.js\n create mode 100644 site_libs/quarto-search/autocomplete.umd.js\n create mode 100644 site_libs/quarto-search/fuse.min.js\n create mode 100644 site_libs/quarto-search/quarto-search.js\n create mode 100644 styles.css\norigin  git@github.com:7yl4r/tylar_info.git (fetch)\norigin  git@github.com:7yl4r/tylar_info.git (push)\nTo github.com:7yl4r/tylar_info.git\n   d59f058..799f3a0  HEAD -&gt; gh-pages\n\n(|) Deploying gh-pages branch to website (this may take a few minutes)\n(-) Deploying gh-pages branch to website (this may take a few minutes)\n[✓] Deploying gh-pages branch to website (this may take a few minutes)\nERROR: TypeError: error sending request for url (https://7yl4r.github.io/tylar_info/.nojekyll): connection error: connection reset\n\nTypeError: error sending request for url (https://7yl4r.github.io/tylar_info/.nojekyll): connection error: connection reset\n    at async mainFetch (deno:ext/fetch/26_fetch.js:247:14)\n    at async fetch (deno:ext/fetch/26_fetch.js:464:9)\n    at async file:///opt/quarto/bin/quarto.js:120526:34\n    at async withSpinner (file:///opt/quarto/bin/quarto.js:56614:9)\n    at async Object.publish4 [as publish] (file:///opt/quarto/bin/quarto.js:120520:9)\n    at async publishSite (file:///opt/quarto/bin/quarto.js:121230:38)\n    at async publish5 (file:///opt/quarto/bin/quarto.js:121448:61)\n    at async doPublish (file:///opt/quarto/bin/quarto.js:121404:13)\n    at async publishAction (file:///opt/quarto/bin/quarto.js:121440:13)\n    at async Command.fn (file:///opt/quarto/bin/quarto.js:121392:9)\nIt looks like the site did deploy however, and running the command again works normally."
  },
  {
    "objectID": "posts/2023-12_quarto-blog-config/index.html",
    "href": "posts/2023-12_quarto-blog-config/index.html",
    "title": "Quarto Blog Config",
    "section": "",
    "text": "Created a template for posts and a cheatsheet I can copy-paste from for this blog. Looked at using cookiecutter for creating the post but decided that was overkill. The project focuses mostly on whole-directory templates; I think using jinja might be the preferred way to handle single files."
  },
  {
    "objectID": "cheatsheet.html",
    "href": "cheatsheet.html",
    "title": "tylar.info",
    "section": "",
    "text": "This is a cheatsheet of things I might want ot copy-paste\n# create new blog post\nsource fn.sh && newPost postNameHere\n\n# push gh-pages\nquarto publish gh-pages --no-prompt --no-browser"
  },
  {
    "objectID": "posts/2024-01_rainbow-river-2024-01/index.html",
    "href": "posts/2024-01_rainbow-river-2024-01/index.html",
    "title": "Rainbow River Trek 2024-01",
    "section": "",
    "text": "January is a good time to find manatees in the springs so let’s plan a trip.\nIt is a 1h47m drive according to gmaps.\nMost convenietly located FL WMA is Potts Preserve. It is a 30m drive from the campsite to Rainbow River. * SWFMD Recreation Map * FL WMAs\nFor campsites I checked * hipcamp * reserveAmerica * the above linked WMA map\nI got overwhelmed, gave up trying to find a SWFMD spot, and just booked at the official Rainbow River Campground."
  },
  {
    "objectID": "posts/2023-12_imars-rsclass-2023/index.html",
    "href": "posts/2023-12_imars-rsclass-2023/index.html",
    "title": "{{POSTTITLE}}",
    "section": "",
    "text": "Students of the USF remote sensing course completed projects using google earth engine in order to attempt classification of benthic cover. Projects included:\n\n\n\n\n\n\n\n\n\nproject\nbenthic habitat or variable targeted\nsat source(s) used\ntarget ROI(s)\n\n\n\n\nMostafa\nprimary productivity\nMODIS VGPM 8d 9km\nFlorida Keys\n\n\nAngelique\nCoral Cover\n\nJobos Bay, PR\n\n\nChelsea\nturbidity\nSentinel2\nUSVI\n\n\n\nAngelique\nTitle: Jobos Bay National Estuarine Research Reserve: Seagrass & Reef classification\nDescription: Evaluate habitat distribution in Jobos Bay NERR using a thematic map showing reef and seagrass classification.\nRosealyn\nTitle: Mapping Coral Reefs in the Florida Keys\nDescription: The aim of this project is to create a map of the Florida Keys showcasing coral coverage in 2020. I am using ground-truth data from the NOAA CREMP database and satellite imagery from Sentinel-2.\nClaudia\nTittle: Mangrove cover change in Placencia Belize from 2014 to 2023\nDescription: Use of thematic maps to explore mangrove cover change in 9 years.\nMostafa\nTitle: Comparing Net Primary Productivity: Satellite vs. In Situ Data in the Florida Keys (2015-2020)\nDescription: utilizing net primary productivity (NPP) derived from in situ data collected during MBON cruises and contrasted it with NPP obtained from the MODIS satellite product."
  },
  {
    "objectID": "posts/2024-01_gee-rbnerr-wv-image-choosing/index.html",
    "href": "posts/2024-01_gee-rbnerr-wv-image-choosing/index.html",
    "title": "Choosing Images for Rookery Bay NERR in GEE",
    "section": "",
    "text": "Today I am working to select the “best” satellite images for input into a machine learning model. We want full coverage of the RBNERR area but we are also looking for consistency between images.\nA display of how evenly the area is covered is shown below:\nexports.displayIC = function(d){\n  var imageCollection = d.imageCollection;\n  var sumImg = imageCollection.count();\n  Map.addLayer(\n    sumImg\n    {min: 1, max: 51},\n  )\n  Map.centerObject(sumImg)\n}\n\nvar rookery = require(\n  \"users/tylarmurray/rois:RBNERR\"\n)\nexports.displayIC({\n  imageCollection: rookery.wv_image_collection\n})\nThe centerObject call left things very zoomed out but this works well otherwise. I have reduced the opacity a bit in the following screenshot so the basemap can show through slightly.\n\n\n\ncovermap\n\n\nI am struggling to choose a method for identifying the best subset of images. It was suggested to limit by season but it is unclear to me how to choose which season is best.\nI ran the code again but on an image collection that has been cloudmasked. I added this little function to the users/tylarmurray/rois/RBNERR namespace:\n// return a clean & normalized WV imageCollection.\nexports.getCleanWVImageCollection = function(){\n  var wv_fns = require('users/tylarmurray/sat_fns:wv_fns');\n\n  return exports.wv_image_collection\n    .map(wv_fns.convertToRatios)  // normalization\n    .map(wv_fns.cloudMaskImage)  // cloudmask\n  ;\n}\nThe new image shows much more detail than it should:\n\n\n\ncovermap w/ cloudmask\n\n\nThis means that the cloudmask function is false-positive masking non-clouds often enough for the details to show up here. The amount of detail leaking through is concerning."
  },
  {
    "objectID": "posts/2024-01_bbbb-electrical-victron-connection/index.html",
    "href": "posts/2024-01_bbbb-electrical-victron-connection/index.html",
    "title": "Bus Victron Electrical Connection",
    "section": "",
    "text": "Working to install shore power on the bus today. I wired up the following circuit\nAfter flipping it on I got not power at the outlet. The main tested working; there are no indicator lights on the fuse or breaker to help me debug. I have decided to try going through the fuse to the victron because it has indicator lights.\nAfter inspecting the AC in & AC out connections it looks as though I need a particular type of connector. note: I later found this was not the case. The manual does not specify what kind of connector it is. In this forum post acs calls it a “GST18 connector”. I have the 50A variant of the multiplus-II with 4-wire split-phase connectors but all the diagrams and photos I am seeing have 3-wire; I have the wrong manual. I am feeling anxious about connecting the unit without the 4th wire; I do not know if it was designed to function this way. I found the right manual and it does indeed say “The AC input can be supplied from a split-phase 120/240V source or a single-phase 120V source.” A big sigh of relief for that."
  },
  {
    "objectID": "posts/2024-01_bbbb-electrical-victron-connection/index.html#wiring-up-ac-in",
    "href": "posts/2024-01_bbbb-electrical-victron-connection/index.html#wiring-up-ac-in",
    "title": "Bus Victron Electrical Connection",
    "section": "wiring up ac in",
    "text": "wiring up ac in\nI found a great install video here. Turns out these are “spring connectors” that the wire actually can go into directly.\nStandard colored NEMA wires should be connected like so:\nwhite -- neutral --&gt; N\nred   -- line 2  --&gt; L2 \ngreen -- ground  --&gt; PE\nblack -- line 1  --&gt; L1\n\n\n\ninverter-ac-in-wires-disconnected\n\n\n\n\n\ninverter-ac-in-wires-connected"
  },
  {
    "objectID": "posts/2024-01_bbbb-electrical-victron-connection/index.html#wiring-the-plug-and-breaker",
    "href": "posts/2024-01_bbbb-electrical-victron-connection/index.html#wiring-the-plug-and-breaker",
    "title": "Bus Victron Electrical Connection",
    "section": "wiring the plug and breaker",
    "text": "wiring the plug and breaker\nNext I need to talk about bonding the neutral and ground wires.\nNeutral and Ground should be bonded in only 1 place to prevent ground loops. * neutral/ground is bonded at the shore panel, not inside the RV * neutral/ground is bonded at the generator, not inside the RV\nSo basically, the ground connects to the chassis, and the neutral is treated as an isolated circuit in the RV. Neither the ground nor neutral should be breakered, so I am using a 2-pole breaker to break the two hot wires coming in.\n\n\n\nexterior-breaker-n-plug\n\n\nI want to add a housing around this; an old toolbox or something would work."
  },
  {
    "objectID": "posts/2024-01_bbbb-electrical-victron-connection/index.html#wiring-the-batteries",
    "href": "posts/2024-01_bbbb-electrical-victron-connection/index.html#wiring-the-batteries",
    "title": "Bus Victron Electrical Connection",
    "section": "wiring the batteries",
    "text": "wiring the batteries\nWith default victron configuration I am uncomfortable hooking up my battery. The configuration is set for “Victron Gel Deep Discharge”, which works best for: * Victron AGM Deep Discharge * other AGM batteries * many types of flat-plate flooded batteries\nI do not know the details of the “DEESPAEK 12V LiFePO4 Battery 200Ah w/ integrated BMS, 4k+ Deep Cycles” battery I purchased from amazon."
  },
  {
    "objectID": "posts/2024-01_bbbb-electrical-victron-connection/index.html#victron-operation",
    "href": "posts/2024-01_bbbb-electrical-victron-connection/index.html#victron-operation",
    "title": "Bus Victron Electrical Connection",
    "section": "Victron operation",
    "text": "Victron operation\nNow let’s get the victron running.\nThe unit has a switch with three settings: * I : on * 0 : off * II : charger only\nTo change configuration from the factory settings an “Interface MK3-USB (VE.Bus to USB)” is needed. These run about 70$."
  },
  {
    "objectID": "posts/2026-01_st-andrews-seagrass-time-series/index.html",
    "href": "posts/2026-01_st-andrews-seagrass-time-series/index.html",
    "title": "Seagrass Time Series for St Andrew’s Bay, FL",
    "section": "",
    "text": "An attempt was made to visualize seagrass change in select regions of St Andrew’s Bay using Sentinel 2 imagery.\nThe imact of Hurricane Michael seems apparent, but then the question is: what happened in 2021?\nTwo areas of seagrass loss between 2020 and 2024 were manually identified using the IMaRS SIMM project seagrass .tif files.\nSentinel images were cloudmasked and the mean was taken from within these areas using this GEE script.\nThe resulting values were downloaded as a .csv and imported into this gsheet.\nThe visualizations there were screenshotted into Inkscape and manually annotated."
  },
  {
    "objectID": "posts/2026-01_st-andrews-seagrass-time-series/index.html#more-on-seasonality",
    "href": "posts/2026-01_st-andrews-seagrass-time-series/index.html#more-on-seasonality",
    "title": "Seagrass Time Series for St Andrew’s Bay, FL",
    "section": "More on Seasonality",
    "text": "More on Seasonality\nThe apparent seasonality in the series is could be explained by seagrass growth patters, water quality changes, and changing optical properties. To explore this further an offshore area was selected to use as a baseline reference region. A small modification was made to the previous GEE script to create a script which extracts the deep water region.\nThe NDSVI extracted from the deep water region was subtracted from the seagrass area NDSVI.\n\n\n\nndsvi-deepWaterCorrected\n\n\nThe resulting “corrected” signal retains strong seasonality. The “hurricane Michael” event is more prominent in this series.\n\nThe same method was applied for an area of “deepish” water from within the sound. This baseline reference area should include changes in optical properties and water quality.\n\n\n\nndsvi-deepishWaterCorrected\n\n\nThe remaining seasonality indicates that the seasonal signal of the seagrass area is stronger than the seasonality a nearby area of “deepish” water. In this series the “hurricane Michael” event is characterized by a sudden drop in NDSVI during the hurricane, followed by a missing winter peak."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html",
    "href": "posts/2025-12_prithvi-seagrass/index.html",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "",
    "text": "An attempt to fine-tune Prithvi-EO using IMaRS SIMM project seagrass maps.\nThis work is based on this Prithvi-EO notebook."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#background",
    "href": "posts/2025-12_prithvi-seagrass/index.html#background",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "Background",
    "text": "Background\n\nThe SIMM Seagrass Project\nFrom the SIMM Seagrass project two images are obtained of the St Andrew’s sound region.\n\nA seagrass classification .tif created using the mode of classifications on images taken throughout a year.\nA spectral mean .tif created using the same images used to generate classifications.\n\nThe aggregations use a total of 138 images covering 2022-2024, one aggregation is created for each year.\nThe 2024 year is selected for creating this dataset. The 2024 spectral mean image is built from 72 images. This image cannot be shared due to licensing restrictions.\nThe seagrass image can be downloaded here. From the SIMM Seagrass project two images are obtained of the St Andrew’s sound region.\n\nA seagrass classification .tif created using the mode of classifications on images taken throughout a year.\nA spectral median .tif created using all Planet SuperDove images (346 images).\n\nThe spectral mean image cannot be shared due to licensing restrictions. The GEE script to generate this image is here. This script will not work unless you have access to the (restricted) Planet SuperDove image collection asset.\nThe seagrass image for 2024 can be downloaded here. In addition to application of the seagrass classifier (GEE script available here), manal adjustments may have been made to improve the final product."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#create-training-dataset",
    "href": "posts/2025-12_prithvi-seagrass/index.html#create-training-dataset",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "Create Training Dataset",
    "text": "Create Training Dataset\nThe first training dataset created used Planet imagery, so the spectra do not align perfectly with Prithvi’s knowledge (based on Sentinel & Landsat). Later versions focused only on sentinel imagery.\nThe notebook expects input data for fine-tuning in the ../data/ directory. These files should be in pairs like:\n\nchip_025_082.mask.tif\nchip_025_082.merged.tif\n\nThe mask is the classification (seagrass yes/no). The merged file is the spectral bands.\n\nAttempt (1) : Google Earth Engine\nTo create a fine-tuning dataset of patches, the GEE addSeagrass method developed for the SIMM Seagrass project along with the planet superdove imagery already ingested into GEE are used. The spectral images and the seagrass layer produced need to be cut into patches.\nAn initial attempt to create this script with ChatGPT (transcript here) failed.\nAn attempt to work with Claude to accomplish this (artifact here) ended in moderate success. Patches can be exported with one GEE task per patch in batches. This necessitates clicking run on every patch export. For a few 100 patches this is fine, but it is recommended to tune with a minimum of 1000 patches.\nThe python API allows automatic starting of tasks, but the generation of the seagrass maps is done in GEE javascript. The .tif outputs of these scripts can be used locally rather than using GEE to chunk up the images into patches.\n\n\nAttempt (2) : Cutting patches with python\nThe SVM classification as described above should be annual_median_selectedBands_2024.tif.\nThe 8b image is expected to have 3 time-steps in the bands. Three multispectral images from three time points are expected, with bands in the _merged.tif files ordered like\n[t0_b0, t0_b1, ..., t0_b7,\n t1_b0, t1_b1, ..., t1_b7,\n t2_b0, t2_b1, ..., t2_b7]\nA GEE script to create this image using three composite (median) images from for images from years 2023-2025 was created here The seasons were chosen using this ChatGPT query.\n\n\n\n\n\n\n\n\n\n\nSeason\nMonths\nOptical Regime\nSeagrass Detectability\nRecommended Use\n\n\n\n\nHigh Attenuation\nJan–Apr\nHigh CDOM + sediment\nPoor\nAvoid for benthic mapping\n\n\nTransitional\nMay–early Jul\nMixed clarity\nModerate, variable\nSupplemental / temporal fusion\n\n\nPeak Visibility\nLate Jul–Oct\nClear water, deep light\nExcellent\nPrimary training & mapping\n\n\n(Excluded / Variable)\nNov–Dec\nStorm-driven variability\nUnreliable\nUse selectively\n\n\n\nThe Nov-Dec period was excluded. The total images used for each seasonal composite are:\n\nHigh Attenuation (Jan-Apr) - Image count: 46\nTransitional (May-early Jul) - Image count: 10\nPeak Visibility (Late Jul-Oct) - Image count: 92\n\nBased on visual interpretation of the true-color display, the seagrass areas appear to have different spectral signatures in the seagrass regions for each season. This added temporal information should increase the accuracy of the foundation model’s classification product.\nThe resulting images do have some artifacts; the lines between passes are noticeable.\nThe resulting export is saved as 9 shards because a single .tif would be too large. The download from gdrive comes in multiple parts because a single .zip would be too large. After unzipping each .zip, the files are put into a single directory and used with the extract_tuning_patches.py script.\nPreparation of tuning patches was completed with this script.\nThe patches were then compressed (tar -cvjf data/seagrass_tuning_patches.tar.bz2 data/tuning_patches) and the compressed file was uploaded to Google Drive."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#fine-tuning-and-using-the-model",
    "href": "posts/2025-12_prithvi-seagrass/index.html#fine-tuning-and-using-the-model",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "Fine-tuning and using the model",
    "text": "Fine-tuning and using the model\nA jupyter notebook prithvi_v2_eo_300_tl_unet_seagrass.ipynb was created from the prithvi_v2_eo_300_tl_unet_multitemporal_crop.ipynb starting point. Modifications were made to :\n\nload the training dataset\ncreate relevant classes derived from Crop classification classes\n\n\nadd required means and std_dev for each band. (see below)\n\nit is assumed these are calculated from patch chips.\na script to do this calculation was created: calculate_chip_statistics.py\n\n\n\napply model to an unseen image to create classification\n\n\nMean and Std_dev calculations for each band\nThe .ipynb expects mean and std_dev statistics for each band. I do not have a good understanding of what these statistics are and what purpose they serve in the .ipynb. It seems safe to assume they are for data normalization. The values being used are from a median image made from the year 2024. It is assumed that these values are not significantly different than if statistics were calculated on all 24 (8 spectral x 3 temporal) bands reduced across the temporal dimension into 8 statistics. The calculate_chip_statistics.py script could be updated to do this calculation. It is expected that the values would be very similar to the “legacy” values currently in the .ipynb.\n\n\nUnseen Training Image\nThe aforementioned GEE script used to generate 3-time-step seasonal images was used with images for the year 2020. This is entirely unseen by the model (which was generated from a median taken 2023-2025).\nThe image is saved to google drive from the script, and the filepath is used in the .ipynb to download the image into the colab runtime.\nThe model is run on the image to produce a seagrass classification image."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#v01",
    "href": "posts/2025-12_prithvi-seagrass/index.html#v01",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "v01",
    "text": "v01\nInitial results from the classifier are poor quality.\n\n\n\nv01 map\n\n\nThe classifier seems to be identifying water and non-water."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#v02-added-land-masking",
    "href": "posts/2025-12_prithvi-seagrass/index.html#v02-added-land-masking",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "v02 : Added Land-Masking",
    "text": "v02 : Added Land-Masking\nTo address this issue the input .tif images are cropped with a land-mask before use. This is applied to both the chip and the to-classify image.\nThe GEE image export script has been updated.\nRunning again after masking shows markedly improved results.\n\n\n\nv02 map\n\n\nThe model has now learned to identify shallow areas, but is not differentiating between sand and seagrass. As a side note: Prithvi might be good at creating bathymetry."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#v05-switch-to-using-sentinel-imagery",
    "href": "posts/2025-12_prithvi-seagrass/index.html#v05-switch-to-using-sentinel-imagery",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "v05 : Switch to using Sentinel Imagery",
    "text": "v05 : Switch to using Sentinel Imagery\nPerhaps it is the usage of Planet SuperDove imagery that is causing issues. We attempt to use sentinel imagery only to create a map.\nBecause sentinel 2 has more images we reduce to using 2024 only.\nHigh Attenuation (Jan-Apr) - Image count:\n23\nTransitional (May-early Jul) - Image count:\n15\nPeak Visibility (Late Jul-Oct) - Image count:\n22\nThe number of valid patches drops significantly due to the lower resolution of the S2 product:\n(base) tylar@tylar-laptop:~/repos/nasa-prithvi-wetlands$ python py/extract_tuning_patches.py \nDetected single TIF file: data/seasonal_s2_stack.tif\n\n============================================================\nProcessing spectral file 1/1: seasonal_s2_stack.tif\n============================================================\nCRS mismatch detected: EPSG:4326 vs EPSG:3746\nReprojecting mask to match spectral image...\nMask reprojected to match spectral image: (1306, 1585)\n\nExtracting 224x224 patches with stride 224\nNumber of spectral bands: 24\nWill extract up to 35 patches from this shard\n\nShard complete: 22 valid patches extracted\n\n============================================================\nExtraction complete!\n============================================================\nSpectral files processed: 1\nValid patches saved: 22\nPatches skipped: 13\nOutput directory: data/tuning_patches\n\nOrganizing patches into training and validation sets...\n\nDataset split created:\nTraining samples: 18\n  - Files in: data/tuning_patches/training_chips\n  - List file: training_data.txt\nValidation samples: 4\n  - Files in: data/tuning_patches/validation_chips\n  - List file: validation_data.txt\n\nChip naming format:\n  - Spectral: chip_XXXXX_merged.tif\n  - Mask: chip_XXXXX.mask.tif\n\nCleaning up temporary directories...\n  - Removed: data/tuning_patches/spectral\n  - Removed: data/tuning_patches/masks\n✓ Cleanup complete!\n\n✓ Patch extraction complete! Ready for Prithvi fine-tuning.\n\n!!! PROBLEM DISCOVERED IN PIPELINE !!!\nThis issue may affect previous versions. The tuning_patches directory is not cleared with each run. Chips existing in the directory before the script is run will be included in the compressed chip file.\nThis may have affected previous multi-class extractions. I am not certain if I manually cleared the tuning_patches directory. The extract_tuning_patches.py script has been updated to clear the directory. ——————\nThe patches are zipped and uploaded to GDrive.\nThe notebook is re-run.\n\n\n\nseagrass-classification-v05\n\n\nNo good."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#simplify-to-2-class-and-sentinel-2-only-imagery",
    "href": "posts/2025-12_prithvi-seagrass/index.html#simplify-to-2-class-and-sentinel-2-only-imagery",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "Simplify to 2-class and Sentinel-2 only imagery",
    "text": "Simplify to 2-class and Sentinel-2 only imagery\nThe pipeline was simplified to identify root cause of poor model performance. A new research notebook was created.\nThe number of seagrass classes is returned to 2 (seagrass, other). The input imagery being used will be derived from sentinel 2 (rather than planet superdove).\n\nNew Spectral Images\nNew spectral images are prepared with GEE users/tylarmurray/prithvi:prithvi_s2_median_tif_collection1.\nfor 2020:\nHigh Attenuation (Jan-Apr) - Image count:\n72\nTransitional (May-early Jul) - Image count:\n44\nPeak Visibility (Late Jul-Oct) - Image count:\n67\nand for 2024:\nHigh Attenuation (Jan-Apr) - Image count:\n74\nTransitional (May-early Jul) - Image count:\n49\nPeak Visibility (Late Jul-Oct) - Image count:\n72\n\n\nNew Tuning Patch-Set\nNew tuning patches were extracted from the 2023-2025 median image and the SIMM seagrass map.\n(base) tylar@tylar-laptop:~/repos/nasa-prithvi-wetlands$ python scripts/extract_tuning_patches_seagrass_2class_sentinel2.py \nClearing existing output directory: data/output/tuning_patches\nDetected single TIF file: data/input/spectral/stAndrews_seasonal_s2_stack_2023_to_2025.tif\n\n============================================================\nProcessing spectral file 1/1: stAndrews_seasonal_s2_stack_2023_to_2025.tif\n============================================================\nCRS mismatch detected: EPSG:4326 vs EPSG:3746\nReprojecting mask to match spectral image...\nMask reprojected to match spectral image: (1306, 1585)\n\nExtracting 224x224 patches with stride 224\nNumber of spectral bands: 24\nWill extract up to 35 patches from this shard\n\nShard complete: 22 valid patches extracted\n\n============================================================\nExtraction complete!\n============================================================\nSpectral files processed: 1\nValid patches saved: 22\nPatches skipped: 13\nOutput directory: data/output/tuning_patches\n\nOrganizing patches into training and validation sets...\n\nDataset split created:\nTraining samples: 18\n  - Files in: data/output/tuning_patches/training_chips\n  - List file: training_data.txt\nValidation samples: 4\n  - Files in: data/output/tuning_patches/validation_chips\n  - List file: validation_data.txt\n\nChip naming format:\n  - Spectral: chip_XXXXX_merged.tif\n  - Mask: chip_XXXXX.mask.tif\n\nCleaning up temporary directories...\n  - Removed: data/output/tuning_patches/spectral\n  - Removed: data/output/tuning_patches/masks\n✓ Cleanup complete!\n\n✓ Patch extraction complete! Ready for Prithvi fine-tuning.\n\nCompressing tuning patches...\n✓ Compressed patches saved to: data/output/stAndrews_seagrass_tuning_patches.tar.bz2\nNOTE: This number of tuning samples may be too low for tuning to be effective.\n\n\nResults\n\n\n\nseagrass-classification-v06\n\n\nThe result shows artifacts at the boundaries of processing tiling. The model is identifying areas nearby to masked areas as likely seagrass.\nA comparison with an un-land-masked image is needed.\nFor this comparison see this post"
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#todo-band-selection",
    "href": "posts/2025-12_prithvi-seagrass/index.html#todo-band-selection",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "TODO: Band Selection",
    "text": "TODO: Band Selection\nAddition of ratio bands and bands with temporal components may be useful for the model. The following are considered for addition:\n\nRatio Medians For Cleaner Signals\nTurbidity Proxy Blue/Green Median & Variance\ncoastal/green\ngreen I / green II\nlog(Blue / Green)\nVariances for Temporal Stability Discrimination\nGreen\nBlue/Green\nMax-min for Temporal Change Magnitude Discrimination\nGreen\n\nIn addition, the NIR and RedEdge could be dropped, as these are likely not useful for underwater cover. Although the NIR may be useful for differentiating water vs land.\nThese modifications should be made to the GEE exporting script so that the new selection of bands will be exported rather than the 8 medians. Because there are 3 time-steps included, the total number of bands will be the number of per-aggregation bands times 3."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#todo-attempt-without-landmask-on-median",
    "href": "posts/2025-12_prithvi-seagrass/index.html#todo-attempt-without-landmask-on-median",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "TODO: attempt without landmask on median",
    "text": "TODO: attempt without landmask on median\nPerhaps the land-masked median image is causing issues. We attempt to run the classifier with a full image."
  },
  {
    "objectID": "posts/2025-12_prithvi-seagrass/index.html#todo-per-chip-normalization",
    "href": "posts/2025-12_prithvi-seagrass/index.html#todo-per-chip-normalization",
    "title": "Seagrass Mapping with NASA Prithvi-EO",
    "section": "TODO: Per-Chip Normalization",
    "text": "TODO: Per-Chip Normalization\nTo remove the ability of the model to learn on brightness alone, the chips can be normalized independently. Because the overall scene brightness characteristics are removed, the model is forced to focus on texture and shape."
  },
  {
    "objectID": "posts/2024-01_phytoclass-gui-updates/index.html",
    "href": "posts/2024-01_phytoclass-gui-updates/index.html",
    "title": "Phytoclass GUI Updates",
    "section": "",
    "text": "Doing a last-minute attempt at resolving the TODO items I collected in the prototype phytoclass GUI last month. The amount of requested changes feels overwhelming"
  },
  {
    "objectID": "posts/2024-01_researcher-workshops-brainstorming/index.html",
    "href": "posts/2024-01_researcher-workshops-brainstorming/index.html",
    "title": "Brainstorming USF Libraries Researcher Workshop Topics",
    "section": "",
    "text": "I am brainstorming presentation ideas.\nHere is a list of titles: 1. Scientific Method 2.0 : applied scientific modeling in the age of AI 2. data about data : 3. finding your niche in the machine : systems engineering principles 4. Reclaim your data : Personal OpSec & Data management advice 5. How to speak computer : Machine Learning, systems engineering, code languages, and magic\nHere is a list of slide ideas: * underfitting, overfitting issues are pervasive * tech secret vendor lock-in * what is data, what is metadata? * hash functions + content addressable file systems * the semantic web * UML diagramming * user interface design * the linux philosophy * DRY * personal blogging & “research journaling”\nHere is a diagram where I tried getting at the different states of product development with the intention of talking about vendor lock-in and the incentives put onto code “owners”.\n---\ntitle: State Diagram for a Digital Products Creators\n---\ngraph TD\n\nstart((startup))\n%% MVP addresses &gt;=1 use case\nwriteCode(\"working on the magic\")\nsellCode(\"sold the magic\")\n\nleaseCode(\"sell use of \\n the magic\")\n\ndemoCode(\"give away the magic\")\n\n%% ======\nstart --&gt; writeCode\n\nwriteCode --&gt; sellCode\n\nwriteCode --&gt; leaseCode --&gt; writeCode\n\nwriteCode --&gt; demoCode --&gt; writeCode\nI am stuck at how to represent different levels of solution obfuscation and data harvesting in this diagram and I think I have lost sight of the purpose of this diagram. I need to take a step back and reconnect with what I want to communicate.\nHere is a bulleted list that inexplicably feels relevant: * data * metadata ontologies rely on a common semantic understanding * the problem of naming things * the “semantic web” makes the source of our shared understanding explicit * LLMs include mathematically encoded semantics\nBut what do I really want to communicate to anybody doing research? * The importance of establishing trusted sources of information. * Remembering your inability to perceive an objective reality\nHere is a screenplay:\nEXT.  UNIVERSE - DARK\n\nA pure black screen.\n\nNARRATOR\nThis is a representation of the universe.\nIn this representation the information needed to explain everything is stored entirely in time.\nWe can sit here and let I can talk for an infinite amount of time until I have explained everything to you but it is not much to look at.\nLet's convert some of the information into space.\n\nA single white speck pops into existence in the center of the screen.\n\nNARRATOR\nA single point in space existing only for the tiniest infinitesimal of time.\nThat point has no meaningful spatial dimensions, but we have made it a little bigger so you can see it.\nThis is a unified grand theory looks like in spacetime.\nOne single piece of raw data that we can plug into a time equation that would define everything yet to happen to this point.\nThe realities of space and time are intertwined in ways that render the universe computationally irreducible.\nThis is not a model of all space and time as viewed from an omnipotent persepective.\nThis is a model of everything as it is viewed from a conscious perspective - filling not both space *and* time - but filling space *or* time.\n\nThe speck grows into a circular white line.\nAs the circle grows it begins fading from bright white into hues into red and blue representing hotter and colder areas in the cosmic microwave background.\nThe circle stops growing.\n\nNARRATOR\nThis circle has spatial dimension because we have used up some time to create it.\nYou have observed the passage of time, the expansion of space, and now your reference frame is no longer that of a single point.\nThe representational model we created is stored in the color of the points along the circle.\nSee the whole circle all at once by focusing on the center but percieving the outer limits.\nFocus your perspective on a single point along the edge to inspect it more closely.\nHold in your mind this single spatial frame of reference.\nBe the circle.\n\nThe circle disappears.\n\nNARRATOR\n...and whatever else time has in store.\n\nRevisiting this 2024-01-07 and I wrote the following:\n\nTrust and Citations in Academic Publishing: Workshop Guide\n\n\ncommand line basics\nAn introduction to command-line interfaces and basic POSIX commands. The workshop will cover the fundamentals of navigating the command line, executing commands, manipulating files and directories, and using command-line tools for various tasks.\n\n\nintro to scientific computer programming for research\nAn introduction to tools available for researchers.\n\n\nReproducibility in Data Analysis\nHow to maximize the reproducibility of your results. A guide to implementing best practices in data analysis, including documentation, version control, and sharing code and data.\n\ngetting a computer to do something is a translation problem\n.\n\n\n\nData Visualization\n\n\nUser Experience Design for Research\n\n\ncommanding computers\nAs AI becomes increasingly accessible An introduction to command-line interfaces and basic POSIX commands. The workshop will cover the fundamentals of navigating the command line, executing commands, manipulating files and directories, and using command-line tools for various tasks.\n\n\nReproducibility in Data Analysis\nHow to maximize the reproducibility of your results. A guide to implementing best practices in data analysis, including documentation, version control, and sharing code and data.\nhow to cite a superintelligence : why we cite\nscience-&gt; know (Latin) skepticism-&gt;search (Greek) cite -&gt;call (Latin)\nscientific thinking means having a huge amount of skepticism. trust absolutely only what your own data says. if you are to trust words, then you must establish sufficient shared experience. the most trustworthy scientific claims are ones you can and have tested yourself.\nAn ideal scientific publication makes one specific claim so well that any reader would be convinced, and so concisely that it would be an entertaining read.\nProblem: audience. We must rely on shared experiences to establish trust. This works best if you mostly already agree with the author. Citations can be used as a way to establish trust by citing authors, publishers, or results that the reader already agrees with. Word choice and use of familiar jargon can also establish a sense of shared experience with the reader.\nProblem: data. We must always be skeptical of data. Do we trust those who collected and published it? Can we collect it ourselves?\nHeuristic: - citing a person. means you have evaluated the trustworthiness of a person. - citing an org says I trust everyone in this org and the mechanations of the org - citing an AI says I trust everyone who contributed to the training data and the modeling method being used\nfact citation provenance\ntypes of citations • define a term (see here for clarification) • substantiate a claim (see here for justification) • data source (see here for raw data) • code\nAs a reader I want to __ so that __ - lookup the definition of a term - investigate the legitimacy of a claim - reproduce some results presented -"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "tylar.info",
    "section": "",
    "text": "Seagrass Change Over Time in FL Bay\n\n\n\n\n\n\n\n\nJan 29, 2026\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nSeagrass Time Series for St Andrew’s Bay, FL\n\n\n\n\n\n\n\n\nJan 16, 2026\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nMangrove Mapping with NASA Prithvi-EO\n\n\n\n\n\n\n\n\nDec 28, 2025\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nShould Land Masking Be Applied for GeoFM Tuning Datasets?\n\n\n\n\n\n\n\n\nDec 28, 2025\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nSeagrass Mapping with NASA Prithvi-EO\n\n\n\n\n\n\n\n\nDec 12, 2025\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nLaptop HDD RePartition\n\n\n\n\n\n\n\n\nFeb 20, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nChoosing Images for Rookery Bay NERR in GEE\n\n\n\n\n\n\n\n\nJan 25, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nCalCOFI Server Clone Attempt\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nPhytoclass GUI Updates\n\n\n\n\n\n\n\n\nJan 16, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nRainbow River Trek 2024-01\n\n\n\n\n\n\n\n\nJan 15, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nBrainstorming USF Libraries Researcher Workshop Topics\n\n\n\n\n\n\n\n\nJan 4, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nBus Victron Electrical Connection\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nGEE DwC-like Ground Truth for USVI Corals\n\n\n\n\n\n\n\n\nDec 28, 2023\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Blog Config\n\n\n\n\n\n\n\n\nDec 27, 2023\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Blog Init\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\nTylar\n\n\n\n\n\n\n\n\n\n\n\n\n{{POSTTITLE}}\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nTylar\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "archived_posts/sinewave-residual-modulation/index.html",
    "href": "archived_posts/sinewave-residual-modulation/index.html",
    "title": "SineWave Residual Modulation",
    "section": "",
    "text": "I had the “opportunity” to spend many hours alone with my own thoughts over the last month. I spent much of the time imagining how I would transmit a signal if I were wanting to contact aliens. What I came up with may not be particularly novel since I am not a signal processing expert but hopefully this writing won’t upset my grad school professors on the subject too much.\nWe start with a repeating signal to give us a method of synchronizing clocks between locations. A more capable civilization might modulate the wavelet of a pulsar but my soft human meat brain likes to imagine a sine wave to serve as this timing wave. From this wave we can easily detect a frequency (f) and express it as a period (T).\nMy idea from there is to capture the residual fluctuations over the wave and average them. For symmetrical waves like sinusoidal waves the first half of the wave can be added to the second half (half-period residual modulation detection). But in general any given wavelet would be differenced from the next to produce a set of residuals (full period residual modulation detection).\nAs far as I know this is not something that can be accomplished with analog signal processing. The signal must be stored for at least the full period T and then combined with the next wavelet instance. The collection and storage of the signal will have a certain bitrate, which must be higher than the timing wave. It is not clear to me what bitrate would be the ideal choice for a given timing frequency. Bigger always seems better but I remain uncertain how to encode universally interpretable information in a time series, regardless of the bitrate. One ideal would be to transmit a signal with similar meaning at multiple bitrates - a lower resolution vs a higher resolution of the same meaning. Could the antenna bandwidth characteristics somehow imply an ideal bitrate? Maybe there is something to be figured related to the maximum throughput or channel capacity of the proposed signal processing paradigm. Or perhaps using a known distance to the transmitter could give you a sense of what sampling frequency would be reasonable to expect.\nAnyway, this is how I would get started if I was leading a new SETI project. Aim something at a pulsar and start crunching on this.\n\n\n\nwavelet_residual_am_image"
  },
  {
    "objectID": "archived_posts/semantic-brain-fart/index.html",
    "href": "archived_posts/semantic-brain-fart/index.html",
    "title": "The Semantic-Web-to-AI Brain Fart Pipeline",
    "section": "",
    "text": "Today I am musing on semantic web tools again. Specifically I want to build a simple e-commerce site with semantic elements built into the inventory system. I posted on the discord of the “Lit” framework (my current favorite web components community) but nobody has replied.\nI went down a long rabbit hole trying to figure out how to build this thing, then decided that running the data through an AI would be better than getting all caught up on how to structure the data.\nThis feels like a pointless exercise I have gone through countless times over the last year or five; every time I start building something it gets more and more complex until I am overwhelmed. Trying to figure out the best way to build the user experience keeps landing me at AI and mesh-networked-IoTs. Those topics remain too big for me to tackle until I have collaborators. And so… I give up and go try to make my space more presentable. I am no longer able to maintain focus without another active participant and this stuff is way too far removed from anyone I know.\nBelow are a bunch of disjointed things I wrote while trying to get my thoughts together.\n\nHere is a lil sales pitch:\nYour personal reviews and recommendations are of more value today than ever.\nThis project allows you to reclaim ownership over that data.\nRecommend the works you trust, give discounts to your friends, and take commission for your influences.\n\nHere are the user stories for the minimum viable product:\n\nFind my preferred product supplier\n\nUser states: I want X\nSystem asks: Who do you trust about X?\n\nPublish an opinion\n\n\n\n\nWho do you trust to ask for a recommendation on X?\nNetwork of trusted suppliers, where each “supplier”\n\nI want to eliminate the process of getting multiple pricing quotes from untrusted suppliers.\n\nTo reduce that goal down a bit: I want to record my opinions about products I have viewed and reviewed so that I can order them again or share them with friends. Maybe there is a way to do this with …"
  }
]